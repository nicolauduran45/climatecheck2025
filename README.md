# ClimateCheck Scientific Claim Verification 
This repository contains code for the ClimateCheck shared task at SDP Workshop (ACL 2025), focused on scientific fact-checking of social media posts about climate change.

##  ğŸ§ª Task Overview
- **Subtask I**: Abstract Retrieval ğŸ“š - retrieve top 10 relevant abstracts for climate change claims
- **Subtask II**: Claim Verification âœ…âŒâ“ - classify claim-abstract pairs as 'support', 'refutes', or 'not enough information'

## ğŸš€ Getting Started
```bash
# Clone repository
git clone [https://github.com/your-username/climatecheck.git](https://github.com/nicolauduran45/climatecheck2025)
cd climatecheck

# Set up environment
python -m venv venv
source venv/bin/activate 
pip install -r requirements.txt

# Download datasets
python src/data/download.py
```
## ğŸ“ Repository Structure
```
climatecheck/
â”œâ”€â”€ configs/                  # Configuration files for experiments
â”œâ”€â”€ data/                     # Dataset storage and processing
â”‚   â”œâ”€â”€ raw/                  # Original datasets
â”‚   â”œâ”€â”€ processed/            # Processed datasets
â”‚   â””â”€â”€ knowledge_graph/      # Knowledge graph files
â”œâ”€â”€ experiments/              # Experiment scripts
â”‚   â”œâ”€â”€ retrieval/            # Subtask I experiments
â”‚   â””â”€â”€ verification/         # Subtask II experiments
â”œâ”€â”€ models/                   # Model implementations
â”‚   â”œâ”€â”€ retrieval/            # Retrieval models
â”‚   â”œâ”€â”€ verification/         # Verification models
â”‚   â””â”€â”€ shared/               # Shared model components
â”œâ”€â”€ notebooks/                # Exploratory notebooks
â”œâ”€â”€ outputs/                  # Experiment outputs
â”‚   â”œâ”€â”€ runs/                 # Training runs
â”‚   â”œâ”€â”€ predictions/          # Model predictions
â”‚   â””â”€â”€ analysis/             # Result analysis
â”œâ”€â”€ references/               # Intersting papers for literature review
â”‚   â”œâ”€â”€ retrieval/            # About scientific claim retrieval 
â”‚   â”œâ”€â”€ verification/         # About scientific claim verification
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ data/                 # Data processing utilities
â”‚   â”œâ”€â”€ knowledge/            # Knowledge graph construction
â”‚   â”œâ”€â”€ evaluation/           # Evaluation metrics and tools
â”‚   â””â”€â”€ utils/                # Shared utilities
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ¤ Contribution Guidelines
1. Branching Strategy
- `main`: Stable code
- `dev`: Development branch
- Feature branches: `feature/your-feature-name`
- Experiment branches: `exp/experiment-name`

2. Experiments
- Store configs in `configs/`
- Save outputs to `outputs/runs/[exp_name]/`
- Include a README in experiment folders

## ğŸƒâ€â™‚ï¸ Running Experiments
```bash
# Run retrieval experiment
python -m src.run_experiment --config configs/retrieval/dense_retrieval_document_specter.yaml
# Run verification experiment

# Run end-to-end pipeline
```

## ğŸ“š Datasets
- Training/Testing: https://huggingface.co/datasets/rabuahmad/climatecheck
- Publications Corpus: https://huggingface.co/datasets/rabuahmad/climatecheck_publications_corpus

## ğŸ—“ï¸ Important Dates
- Training set release: April 1, 2025
- Test set release: April 15, 2025
- Systems submissions deadline: May 16, 2025
- Paper submission deadline: May 23, 2025
